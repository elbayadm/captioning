<table>
    <tr>
        <th>Model</th>
        <th>CNN</th>
        <th>params</th>
        <th>loss</th>
        <th>weights</th>
        <th>Beam</th>
        <th>CIDEr</th>
        <th>Bleu4</th>
        <th>Perplexity</th>
        <th>best/last</th>
    </tr>
    <tr>
        <td>adaptive_attention</td>
        <td>resnet152</td>
        <td> base lr: 1.0e-04 decay: 5, Adam(0.8,0.999), batch: 10, seq: 16</td>
        <td> Combining losses,  Word Level, Sim=Coco, $\tau=0.17$, $\alpha=0.3$ w/ SampleR, r=hamming limited=1 $\tau=0.17$, $\alpha=0.2$</td>
        <td>RNN + 1.0 x cnn(6:)</td>
        <td>3</td>
        <td>99.12</td>
        <td>31.71</td>
        <td>133.97</td>
        <td>176k / 248k</td>
    </tr>
    <tr>
        <td>adaptive_attention</td>
        <td>resnet152</td>
        <td> base lr: 5.0e-04 decay: 5, Adam(0.8,0.999), batch: 10, seq: 16</td>
        <td> Combining losses,  Word Level, Sim=Coco, $\tau=0.17$, $\alpha=0.4$ w/ SampleR, r=hamming limited=1 $\tau=0.17$, $\alpha=0.5$</td>
        <td>RNN</td>
        <td>3</td>
        <td>94.05</td>
        <td>30.18</td>
        <td>294.94</td>
        <td>104k / 172k</td>
    </tr>
    <tr>
        <td>adaptive_attention</td>
        <td>resnet152</td>
        <td> base lr: 5.0e-04 decay: 5, Adam(0.8,0.999), batch: 10, seq: 16</td>
        <td> Combining losses,  Word Level, Sim=Coco, $\tau=0.17$, $\alpha=0.3$ w/ SampleR, r=hamming limited=1 $\tau=0.17$, $\alpha=0.5$</td>
        <td>RNN</td>
        <td>3</td>
        <td>93.58</td>
        <td>29.98</td>
        <td>142.61</td>
        <td>100k / 172k</td>
    </tr>
    <tr>
        <td>adaptive_attention</td>
        <td>resnet152</td>
        <td> base lr: 5.0e-04 decay: 5, Adam(0.8,0.999), batch: 10, seq: 16</td>
        <td> Combining losses,  Word Level, Sim=Coco, $\tau=0.17$, $\alpha=0.5$ w/ SampleR, r=hamming limited=1 $\tau=0.17$, $\alpha=0.5$</td>
        <td>RNN</td>
        <td>3</td>
        <td>92.74</td>
        <td>29.64</td>
        <td>585.28</td>
        <td>108k / 172k</td>
    </tr>
    <tr>
        <td>adaptive_attention</td>
        <td>resnet152</td>
        <td> base lr: 5.0e-04 decay: 5, Adam(0.8,0.999), batch: 10, seq: 16</td>
        <td> Combining losses,  Word Level, Sim=Coco, $\tau=0.17$, $\alpha=0.3$ w/ SampleR, r=hamming limited=1 $\tau=0.17$, $\alpha=0.2$</td>
        <td>RNN</td>
        <td>3</td>
        <td>92.56</td>
        <td>30.04</td>
        <td>137.66</td>
        <td>124k / 172k</td>
    </tr>
    <tr>
        <td>adaptive_attention</td>
        <td>resnet152</td>
        <td> base lr: 5.0e-04 decay: 5, Adam(0.8,0.999), batch: 10, seq: 16</td>
        <td> Combining losses,  Word Level, Sim=Coco xIDF, $\tau=0.15$, $\alpha=0.7$ w/ SampleR, r=hamming limited=1 $\tau=0.17$, $\alpha=0.4$</td>
        <td>RNN</td>
        <td>3</td>
        <td>90.97</td>
        <td>29.58</td>
        <td>2028.49</td>
        <td>100k / 172k</td>
    </tr>
</table>